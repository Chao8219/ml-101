{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "%matplotlib inline\n",
    "pyplot.rcParams['font.family'] = 'serif'\n",
    "pyplot.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pandas.read_excel('titanic.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      "pclass       1309 non-null int64\n",
      "survived     1309 non-null int64\n",
      "name         1309 non-null object\n",
      "sex          1309 non-null object\n",
      "age          1046 non-null float64\n",
      "sibsp        1309 non-null int64\n",
      "parch        1309 non-null int64\n",
      "ticket       1309 non-null object\n",
      "fare         1308 non-null float64\n",
      "cabin        295 non-null object\n",
      "embarked     1307 non-null object\n",
      "boat         486 non-null object\n",
      "body         121 non-null float64\n",
      "home.dest    745 non-null object\n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>160.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>14.413500</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>97.696922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived          age        sibsp        parch  \\\n",
       "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
       "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
       "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
       "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
       "25%       2.000000     0.000000    21.000000     0.000000     0.000000   \n",
       "50%       3.000000     0.000000    28.000000     0.000000     0.000000   \n",
       "75%       3.000000     1.000000    39.000000     1.000000     0.000000   \n",
       "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
       "\n",
       "              fare        body  \n",
       "count  1308.000000  121.000000  \n",
       "mean     33.295479  160.809917  \n",
       "std      51.758668   97.696922  \n",
       "min       0.000000    1.000000  \n",
       "25%       7.895800   72.000000  \n",
       "50%      14.454200  155.000000  \n",
       "75%      31.275000  256.000000  \n",
       "max     512.329200  328.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Recognize Hand-write Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 5s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train.shape\n",
    "type(x_train[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "n = 1\n",
    "pyplot.imshow(x_train[n].reshape(28,28),cmap='Greys', interpolation='nearest')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "import sys\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(64, (2,2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 3,156,098\n",
      "Trainable params: 3,156,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have 2 dimensions, but got array with shape (60000, 10, 10, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-45acd7fb4ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml-101-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-101-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-101-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have 2 dimensions, but got array with shape (60000, 10, 10, 10)"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-79c093088a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(12,8))\n",
    "pyplot.plot(hist.history['loss'])\n",
    "pyplot.plot(hist.history['val_loss'])\n",
    "pyplot.plot(hist.history['acc'])\n",
    "pyplot.plot(hist.history['val_acc'])\n",
    "pyplot.legend(['loss', 'val_loss', 'acc', 'val_acc'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
